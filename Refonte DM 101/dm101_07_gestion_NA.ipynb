{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "dst-cell-id": "47ec3841-ae6f-4ccc-990b-3516067e8ead",
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/logo_datascientest.png\" style=\"height:150px\">\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<center><h1> Pandas pour la Data Science</h1></center>\n",
    "<center><h2>  Data cleaning : Nettoyage des Données et Gestion des NAs </h2></center>\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "\n",
    "## Contexte\n",
    "> Lorsque vous allez récupérer des données sur internet, via votre entreprise ou encore que vous effecutez des opérations sur vos données comme des fusions, des groupby .... cela peut générer ce que l'on appelle des **valeurs manquantes**.\n",
    ">\n",
    "> Le **nettoyage des données** et la bonne **gestion des valeurs manquantes** (appelées **[NaN](https://en.wikipedia.org/wiki/NaN)** ou **NA**) sont deux étapes essentielles avant toute analyse sur une base de données.\n",
    ">\n",
    "> L'objectif de ce notebook est de détailler chacune de ces deux étapes afin d'obtenir un `DataFrame` propre et facilement exploitable. <br>\n",
    "> En effet, les bases de données présentent très souvent ce genre de problèmes.\n",
    ">\n",
    "> Pour cela, nous allons nous servir du `DataFrame` **`transactions`** importé dans l'exercice précédent.\n",
    "\n",
    "* **(a)** Importer le module `pandas` sous le nom `pd` et charger le fichier `\"transactions.csv\"` dans le `DataFrame` **transactions**. Les données sont séparées par des **virgules** dans le ficher CSV et la colonne contenant les identifiants est **`'transaction_id'`**.\n",
    "\n",
    "\n",
    "* **(b)** Afficher les 10 premières lignes de `transactions.csv` avec la méthode `head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dst-cell-id": "2359e99b-870a-4c19-a4c9-89f96b159345"
   },
   "outputs": [],
   "source": [
    "# Insérez votre code ici \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "dst-cell-id": "5f0a5864-6d62-424a-ab51-8867ca3f5024",
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "# Importation du module pandas sous le nom pd\n",
    "import pandas as pd\n",
    "\n",
    "# Chargement de la base transactions\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep =',', index_col = \"transaction_id\")\n",
    "\n",
    "# Affichage des 10 premières lignes de transactions\n",
    "transactions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "dst-cell-id": "c670174e-6f83-4e52-8761-8a5a6ee66cf3",
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 1. Nettoyage d'un jeu de données\n",
    "\n",
    "> Dans cette partie nous allons introduire les méthodes de la classe `DataFrame` utiles au nettoyage d'un dataset. Ces méthodes peuvent se regrouper dans trois catégories différentes :\n",
    ">> * **Gestion des doublons** (méthodes `duplicated` et `drop_duplicates`).\n",
    ">>\n",
    ">>\n",
    ">> * **Modification des éléments** d'un `DataFrame` (méthodes `replace`, `rename` et `astype`).\n",
    ">>\n",
    ">>\n",
    ">> * **Opérations** sur les valeurs d'un `DataFrame` (méthode `apply` et clause `lambda`).\n",
    "\n",
    "### Gestion des doublons (méthodes `duplicated` et `drop_duplicates`)\n",
    "\n",
    "> Les **doublons** sont des entrées identiques qui apparaissent **plusieurs** fois dans un dataset.\n",
    ">\n",
    "> Quand nous découvrons un jeu de données il est très important de vérifier **dès le départ** qu'il n'y ait pas de doublons. <br>\n",
    "> La présence de doublons va générer des **erreurs** dans les calculs de statistiques ou le traçage de graphiques.\n",
    ">\n",
    "> Soit **`df`** le `DataFrame` suivant :\n",
    ">\n",
    ">|          | Age  | Sexe |  Taille|\n",
    ">|----------|------|------|--------|\n",
    ">|**Robert**|   56 |   M  |   174  |\n",
    ">|**Mark**  |  23  |   M  |   182  |\n",
    ">|**Alina** |  32  |   F  |   169  |\n",
    ">|**Mark**  |  23  |   M  |   182  |\n",
    ">\n",
    "> La présence de doublons se vérifie à l'aide de la méthode **`duplicated`** d'un `DataFrame` :\n",
    ">\n",
    "> ```py\n",
    "> # On repère les lignes contenant des doublons\n",
    "> df.duplicated()\n",
    ">\n",
    "> >>> 0  False\n",
    ">     1  False\n",
    ">     2  False\n",
    ">     3  True\n",
    "> ```\n",
    ">\n",
    "> Cette méthode renvoie un objet de la classe `Series` de `pandas`, équivalente à une colonne d'un `DataFrame`, qui nous dit pour chaque ligne si elle est un doublon.\n",
    ">\n",
    "> Dans cet exemple, le résultat de la méthode `duplicated` nous informe que **la ligne d'indice 3 est un doublon**, c'est-à-dire que c'est la **copie exacte** d'une ligne précédente, dans ce cas la ligne 1.\n",
    ">\n",
    "> Puisque la méthode `duplicated` nous renvoie un objet de la classe `Series`, nous pouvons lui appliquer la méthode **`sum`** pour compter le nombre de doublons :\n",
    ">\n",
    "> ```python\n",
    "> # Pour calculer la somme de booléens, on considère que True vaut 1 et False vaut 0.\n",
    "> print(df.duplicated().sum())\n",
    "> >>> 1\n",
    "> ```\n",
    ">\n",
    "> La méthode d'un `DataFrame` permettant de supprimer les doublons est **`drop_duplicates`**. <br>\n",
    "> Son en-tête est la suivante :\n",
    ">\n",
    "> `drop_duplicates(subset, keep, inplace)`\n",
    "> \n",
    ">> * Le paramètre `subset` indique la ou les colonnes à considérer pour identifier et supprimer les doublons. Par défaut, **`subset = None`** : on considère **toutes** les colonnes du `DataFrame`. \n",
    ">>\n",
    ">>\n",
    ">> * Le paramètre `keep` indique quelle entrée doit être gardée :\n",
    ">>> * **`'first'`** : On garde la **première** occurence.\n",
    ">>>\n",
    ">>>\n",
    ">>> * **`'last'`** : On garde la **dernière** occurence.\n",
    ">>>\n",
    ">>>\n",
    ">>> * **`'False'`** : On ne garde **aucune** des occurences.\n",
    ">>>\n",
    ">>>\n",
    ">>> * Par défaut, **`keep = 'first'`**.\n",
    ">>\n",
    ">>\n",
    ">> * Le paramètre **`inplace`** (très courant dans les méthodes de la classe `DataFrame`), précise si l'on modifie **directement** le `DataFrame` (dans ce cas `inplace=True`) ou si la méthode renvoie une **copie** du `DataFrame` (`inplace=False`). Une méthode appliquée avec l'argument `inplace = True` est **irréversible**. Par défaut, `inplace = False`.\n",
    ">\n",
    "> <div class=\"alert alert-danger\">\n",
    "<i class=\"fa fa-info-circle\"></i> &emsp; \n",
    "    Il faut être très prudent avec l'utilisation du paramètre <code>inplace</code>. Une bonne pratique est d'oublier ce paramètre et d'affecter le <code>DataFrame</code> retourné par la méthode à un <b>nouveau</b> <code>DataFrame</code> de la manière suivante : \n",
    "></div>\n",
    ">\n",
    "> ```python\n",
    "> df = df.drop_duplicates()\n",
    ">```\n",
    ">\n",
    "> Le paramètre `keep` est celui qui est le plus souvent spécifié. <br>\n",
    "> En effet, une base de données peut avoir des doublons créés à des dates différentes. <br>\n",
    "> On spécifiera alors la valeur de l'argument `keep` pour ne garder que les entrées les plus récentes, par exemple.\n",
    "> \n",
    "> Nous illustrons `df` avec la figure suivante :\n",
    "> \n",
    "> <br>\n",
    ">\n",
    "> <img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/duplicates.png\" style = \"width:400px\">\n",
    ">\n",
    "> Nous illustrons dans les exemples suivants les entrées qui sont **supprimées** par la méthode `drop_duplicates` en fonction de la valeur du paramètre `keep` : \n",
    ">\n",
    "> ```py\n",
    "> # On ne garde que la première occurence du doublon\n",
    "> df_first = df.drop_duplicates(keep = 'first')\n",
    "> ```\n",
    ">\n",
    "> <br>\n",
    ">\n",
    "> <img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/duplicates_first.png\" style = \"width:400px\">\n",
    ">\n",
    "> <br>\n",
    ">\n",
    "> ```py\n",
    "> # On ne garde que la dernière occurrence du doublon\n",
    "> df_last = df.drop_duplicates(keep = 'last')\n",
    "> ```\n",
    ">\n",
    "> <img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/duplicates_last.png\" width=\"400\">\n",
    ">\n",
    "> ```py\n",
    "> # On ne garde aucun doublon\n",
    "> df_false = df.drop_duplicates(keep = False)\n",
    "> ```\n",
    "> <img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/duplicates_false.png\" width=\"400\">\n",
    ">\n",
    "\n",
    "* **(a)** Combien y a-t-il de doublons dans le `DataFrame` transactions ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dst-cell-id": "1ca066de-e1fe-40f3-bb16-7b8ab5279341"
   },
   "outputs": [],
   "source": [
    "# Insérez votre code ici \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "dst-cell-id": "b160f87a-cf3a-4bc9-bea6-de3c4a9abb4b",
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "# Dénombrement des doublons\n",
    "doublons = transactions.duplicated().sum()\n",
    "print(\"Il y a\", doublons, \"doublons dans transactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "dst-cell-id": "9433a57d-53bd-4fd5-96b6-fccb14b83772",
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Les transactions ont été enregistrées dans l'ordre antichronologique, c'est-à-dire que les **premières** lignes contiennent les transactions les plus **récentes** et les dernières lignes les transactions les plus anciennes.\n",
    "\n",
    "* **(b)** Éliminer les doublons de la base de données en ne gardant que la première occurrence.\n",
    "\n",
    "\n",
    "* **(c)** À l'aide des paramètres **`subset`** et **`keep`** de la méthode `drop_duplicates` de `transactions`, afficher la transaction **la plus récente** pour **chaque catégorie de `prod_cat_code`**. Pour cela, vous pourrez enlever tous les doublons de la colonne `prod_cat_code` en ne gardant que les premières occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dst-cell-id": "894e00dc-0b5f-40c8-874e-e45dc0bb4696"
   },
   "outputs": [],
   "source": [
    "# Insérez votre code ici \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "dst-cell-id": "01046f30-2106-488a-a8b9-16e066de3f3d",
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "\n",
    "transactions.drop_duplicates(subset = ['prod_cat_code'], keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "dst-cell-id": "f9b7cd80-fe99-4b4a-9323-d1ff1f38d04b",
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Modification des éléments d'un `DataFrame` (méthodes `replace`, `rename` et `astype`)\n",
    "\n",
    "\n",
    "> La méthode **`replace`** permet de **remplacer** une ou plusieurs valeurs d'une colonne d'un `DataFrame`. \n",
    ">\n",
    "> Son en-tête est la suivante : \n",
    ">\n",
    "> ```python\n",
    "> replace(to_replace, value, ...)\n",
    "> ```\n",
    ">\n",
    ">> * Le paramètre `to_replace` contient la valeur ou la liste de valeurs **à remplacer**. Cela peut être une liste d'entiers, de chaînes de caractères, de booléens, etc...\n",
    ">>\n",
    ">>\n",
    ">> * Le paramètre `value` contient la valeur ou la liste de valeurs **remplaçantes**. Cela peut aussi être une liste d'entiers, de chaines de caractères, de booléens, etc...\n",
    ">\n",
    "> <br>\n",
    "> \n",
    ">  <img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/replace.png\" height=\"400px\">\n",
    ">\n",
    "> <br>\n",
    ">\n",
    "> En plus de modifier les éléments d'un `DataFrame`, il est possible de **renommer** ses colonnes.\n",
    ">\n",
    "> Cela est possible grâce à la méthode **`rename`** qui prend en argument un **dictionnaire** dont les **clés** sont les **anciens** noms et les **valeurs** sont les **nouveaux** noms. <br>\n",
    "> Il faut aussi renseigner l'argument **`axis = 1`** pour préciser que les noms à renommer sont ceux des colonnes.\n",
    ">\n",
    ">```py\n",
    "> # Création du dictionnaire associant les anciens noms aux nouveaux noms de colonnes\n",
    "> dictionnaire = {'ancien_nom1': 'nouveau_nom1',\n",
    ">                 'ancien_nom2': 'nouveau_nom2'}\n",
    ">\n",
    "> # On renomme les variables grâce à la méthode rename\n",
    "> df = df.rename(dictionnaire, axis = 1) \n",
    ">```\n",
    ">\n",
    "> Il est parfois nécessaire de modifier non seulement le nom d'une colonne mais aussi son **type**.\n",
    ">\n",
    "> Par exemple, il se peut que lors de l'importation d'une base de données une variable soit de type chaîne de caractères alors qu'elle est réellement de type numérique. <br>\n",
    "> Il suffit qu'une des entrées de la colonne soit mal reconnue et pandas considèrera que cette colonne est de type chaîne de caractères.\n",
    "> \n",
    "> Cela est possible grâce à la méthode **`astype`**.\n",
    ">\n",
    "> Les types que nous verrons le plus souvent sont :\n",
    ">> * `str` : Chaîne de caractères (`'Bonjour'`).\n",
    ">>\n",
    ">>\n",
    ">> * `float` : Nombre à virgule flottante (`1.0`,  `1.14123`).\n",
    ">>\n",
    ">>\n",
    ">> * `int` : Nombre entier (`1`, `1231`).\n",
    "> \n",
    "> Comme pour la méthode **`rename`**, **`astype`** peut prendre en argument un dictionnaire dont les **clés** sont les **noms des colonnes** concernées et les **valeurs** sont les **nouveaux types** à assigner. <br>\n",
    "> Cela est pratique si l'on veut modifier le type de plusieurs colonnes en même temps.\n",
    ">\n",
    "> Le plus souvent, on voudra directement sélectionner la colonne dont on veut modifier le type et l'écraser en lui appliquant la méthode **`astype`**.\n",
    ">\n",
    "> ```python\n",
    "> # Méthode 1 : Création d'un dictionnaire puis appel à la méthode astype du DataFrame\n",
    "> dictionnaire = {'col_1': 'int',\n",
    ">                 'col_2': 'float'}\n",
    "> df = df.astype(dictionnaire)\n",
    ">\n",
    "> # Méthode 2 : Séléction de la colonne puis appel à la méthode astype d'une Series\n",
    "> df['col_1'] = df['col_1'].astype('int') \n",
    "> ```\n",
    ">\n",
    ">\n",
    "><div class='alert alert-success'>\n",
    "<i class='fa fa-exclamation-circle'></i> &emsp; \n",
    "    Les méthodes <code>rename</code> et <code>replace</code> disposent aussi du paramètre <code>inplace</code> pour effectuer l'opération directement sur le <code>DataFrame</code>. À utiliser avec grande prudence.</div>\n",
    "    \n",
    "* Si vous vous trompez dans le prochain exercice, vous pouvez réimporter et effectuer le prétraitement des exercices précédent en lançant la cellule suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dst-cell-id": "c6a83b95-b6a0-4a73-97ba-3eb762521d9e"
   },
   "outputs": [],
   "source": [
    "# Importation des données\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep =',', index_col = \"transaction_id\")\n",
    "\n",
    "# Suppression des doublons\n",
    "transactions = transactions.drop_duplicates(keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "dst-cell-id": "43416817-2966-4a8f-862d-fb824ce54779",
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* **(d)** Importer le module `numpy` sous le nom `np`.\n",
    "\n",
    "\n",
    "* **(e)** Remplacer les modalités **`['e-Shop', 'TeleShop', 'MBR', 'Flagship store',  np.nan]`** de la colonne **`Store_type`** par les modalités **`[1, 2, 3, 4, 0]`**. On en profitera pour remplacer les nan de la colonne **`prod_subcat_code`**.\n",
    "> La valeur `np.nan` est celle qui encode une valeur manquante. Nous allons remplacer cette valeur par `0`.\n",
    "\n",
    "\n",
    "* **(f)** Convertir les colonnes **`Store_type`** et **`prod_subcat_code`** en type **`'int'`**.\n",
    "\n",
    "\n",
    "* **(g)** Renommer les colonnes `Store_type`, `Qty`, `Rate` et `Tax` avec `store_type`, `qty`, `rate` et `tax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dst-cell-id": "285d0391-3194-45b7-9e3e-68f9f3eb867b"
   },
   "outputs": [],
   "source": [
    "# Insérez votre code ici \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "dst-cell-id": "6c0be0e8-97f0-4406-8ac3-dd2288ee40bf",
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "# Importation des données\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep =',', index_col = \"transaction_id\")\n",
    "\n",
    "# Suppression des doublons\n",
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "## Exercice\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Remplacement des modalités\n",
    "transactions = transactions.replace(to_replace = ['e-Shop', 'TeleShop', 'MBR', 'Flagship store',  np.nan],\n",
    "                                    value= [1, 2, 3, 4, 0])\n",
    "\n",
    "# Conversion des types des colonnes\n",
    "new_types = {'Store_type'       : 'int',\n",
    "             'prod_subcat_code' : 'int'}\n",
    "\n",
    "transactions = transactions.astype(new_types)\n",
    "\n",
    "# Changement de nom des colonnes\n",
    "new_names =  {'Store_type' : 'store_type',\n",
    "              'Qty'        : 'qty',\n",
    "              'Rate'       : 'rate',\n",
    "              'Tax'        : 'tax'}\n",
    "\n",
    "transactions = transactions.rename(new_names, axis = 1)\n",
    "\n",
    "# Affichage des premières lignes de transactions\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "dst-cell-id": "53d514e4-5444-4baf-9d85-5b7811778aca",
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Opérations sur les valeurs d'un `DataFrame` (méthode `apply` et fonctions `lambda`)\n",
    "\n",
    "> Il est souvent intéressant de modifier ou agréger les informations des colonnes d'un `DataFrame` à l'aide d'une opération ou d'une fonction. \n",
    ">\n",
    "> Ces opérations peuvent être tout type de fonction **qui prend en argument une colonne**. <br>\n",
    "> Ainsi, le module **numpy est parfaitement adapté** pour effectuer des opérations sur ce type d'objet.\n",
    ">\n",
    "> La méthode permettant d'effectuer une opération sur une colonne est la méthode **`apply`** d'un `DataFrame` dont l'en-tête est :\n",
    ">\n",
    "> ```python\n",
    "> apply(func, axis, ...)\n",
    "> ```\n",
    ">\n",
    "> où :\n",
    ">> * **`func`** est la fonction à appliquer à la colonne.\n",
    ">>\n",
    ">>\n",
    ">> * **`axis`** est la dimension sur laquelle l'opération doit s'appliquer.\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Exemple :</span> `apply` et `np.sum`\n",
    "> \n",
    "> Pour chaque colonne de type numérique, nous voulons calculer la **somme de toutes les lignes**. <br>\n",
    "> La fonction `sum` de `numpy` effectue cette opération, ce qui nous permet de l'utiliser avec la méthode `apply`.`Python`.  \n",
    ">\n",
    "> Puisque nous allons réaliser une opération sur les **lignes**, il faut donc préciser l'argument **`axis = 0`** dans la méthode `apply`.\n",
    ">\n",
    ">```py\n",
    "> # Somme des lignes pour chaque COLONNE de df\n",
    ">  df_lines = df.apply(np.sum, axis = 0) \n",
    ">```\n",
    "> Le résultat est le suivant : \n",
    "> <img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/apply_sum_lines.png\" style = 'height:300px'>\n",
    ">\n",
    "> <br>\n",
    ">\n",
    "> Dans un second temps, nous voulons pour chaque ligne calculer la **somme de toutes les colonnes**.\n",
    ">\n",
    "> Nous allons réaliser cette opération sur les colonnes, il faut donc préciser l'argument **`axis = 1`** dans la méthode `apply`.\n",
    ">\n",
    ">```py\n",
    "> # Somme des colonnes pour chaque LIGNE de df\n",
    ">  df_columns = df.apply(np.sum, axis = 1) \n",
    ">```\n",
    ">\n",
    "> Le résultat est le suivant : \n",
    "> <img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/apply_sum_columns.png\" style =\"height:280px\">\n",
    ">\n",
    "> <br>\n",
    ">\n",
    "> Ces exemples illustrent l'utilisation de la méthode `apply`. <br>\n",
    "> Pour calculer une somme de lignes ou colonnes, il est préférable d'utiliser la méthode **`sum`** d'un `DataFrame` ou d'une `Series`, qui se comporte exactement de la même façon que la méthode `sum` d'un array numpy.\n",
    ">\n",
    "> <br>\n",
    ">\n",
    "> La colonne `tran_date` de `transactions` contient les dates des transactions au format **`('jour-mois-annee')`** (ex : `'28-02-2014'`). <br>\n",
    "> Ces dates sont de type chaîne de caractères : Il est impossible d'effectuer des statistiques sur cette variable pour l'instant.\n",
    "> \n",
    "> Nous voudrions plutôt avoir dans **3 colonnes différentes** pour les jours, mois et années de chaque transaction. <br>\n",
    "> Ceci nous permettrait par exemple d'analyser et détecter des tendances dans les dates de transaction. \n",
    ">\n",
    "> La date `'28-02-2014'` est une chaîne de caractères. Le jour, le mois et l'année sont séparées par un tiret **`'-'`**. <br>\n",
    "> La classe des chaînes de caractères dispose de la méthode **`split`** pour découper une chaîne sur un caractère spécifique :\n",
    "> \n",
    "> ```python\n",
    "> date = '28-02-2014'\n",
    "> \n",
    "> # Découpage de la chaîne sur le caractère '-'\n",
    "> print(date.split('-'))\n",
    "> >>> ['28', '02', '2014']\n",
    "> ```\n",
    "> \n",
    "> Cette méthode renvoie une **liste** contenant les découpes de la chaîne sur le caractère spécifié. <br>\n",
    "> Ainsi, pour récupérer le jour, il suffit de sélectionner le **premier** élément du découpage. Pour récupérer le mois, il faut prendre le deuxième élément et pour l'année le troisième.\n",
    "\n",
    "* **(h)** Définir une fonction **`get_day`** prenant en argument une chaîne de caractères et qui renvoie le premier élément de son découpage par le caractère `'-'`.\n",
    "\n",
    "\n",
    "* **(i)** Définir les fonctions **`get_month`** et **`get_year`** qui font de même avec le deuxième et troisième élément du découpage.\n",
    "\n",
    "\n",
    "* **(j)** Dans 3 variables **`days`**, **`months`** et **`years`**, stocker le résultat de la méthode **`apply`** sur la colonne **`tran_date`** appliquée avec les fonctions `get_day`, `get_month` et `get_year`. Comme ces fonctions s'appliquent élément par élément, il n'est pas nécessaire de spécifier l'argument **`axis`** dans la méthode `apply`.\n",
    "\n",
    "\n",
    "* **(k)** Créer les colonnes `'day'`, `'month'`  et `'year'` dans le `DataFrame` et y stocker les valeurs de `days`, `months` et `years`. La création d'une nouvelle colonne se fait simplement en la déclarant :\n",
    "> ```python\n",
    "> # Création d'une nouvelle colonne 'day' avec les valeurs contenue dans days.\n",
    "> transactions['day'] = days\n",
    "> ```\n",
    "\n",
    "\n",
    "* **(l)** Afficher les 5 premières lignes de `transactions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dst-cell-id": "977ab197-0792-4377-b0e1-8c5d05e9c20e"
   },
   "outputs": [],
   "source": [
    "## Insérez votre code ici \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "dst-cell-id": "7674329b-151b-43a7-a393-b14d23f230ac",
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "# Définition des fonctions à appliquer à la colonne 'tran_date'\n",
    "def get_day(date):\n",
    "    \"\"\"\n",
    "    Prend en argument une date sous forme de chaîne de caractères.\n",
    "    \n",
    "    La date doit avoir le format 'JJ-MM-AAAA'.\n",
    "    \n",
    "    Cette fonction renvoie le jour (JJ).\n",
    "        \"\"\"\n",
    "    \n",
    "    # Découpage de la chaîne sur le caractère '-'\n",
    "    splits = date.split('-')\n",
    "    \n",
    "    # On renvoie le premier élément du découpage (jour)\n",
    "    day = splits[0]\n",
    "    return day\n",
    "\n",
    "def get_month(date):\n",
    "    return date.split('-')[1]\n",
    "\n",
    "def get_year(date):\n",
    "    return date.split('-')[2]\n",
    "    \n",
    "    \n",
    "# Application des fonctions\n",
    "days = transactions['tran_date'].apply(get_day)\n",
    "months = transactions['tran_date'].apply(get_month)\n",
    "years = transactions['tran_date'].apply(get_year)\n",
    "\n",
    "# Création des nouvelles colonnes\n",
    "transactions['day'] = days\n",
    "transactions['month'] = months\n",
    "transactions['year'] = years\n",
    "\n",
    "# Affichage des premières lignes de transactions\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "dst-cell-id": "0556a94e-8af7-467c-8d61-33be525d894e",
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> La méthode **`apply`** est très puissante lorsqu'elle est associée à une fonction **`lambda`**.\n",
    ">\n",
    "> Les fonctions `lambda` permettent de définir des fonctions avec une syntaxe très courte.\n",
    ">\n",
    "> La définition classique d'une fonction se fait avec la clause **`def`** :\n",
    ">\n",
    ">```py\n",
    "> def increment(x): \n",
    ">    return x+1 \n",
    ">```\n",
    ">\n",
    "> Il est aussi possible de définir une fonction avec la clause **`lambda`** :\n",
    "> \n",
    ">```py\n",
    "> increment = lambda x: x+1\n",
    ">```\n",
    ">\n",
    "> La première est très propre mais l'avantage de la seconde est de pouvoir être définie directement **au sein** de la méthode **`apply`**. \n",
    ">\n",
    "> Ainsi, l'exercice précédent peut être fait avec une syntaxe très compacte :\n",
    ">\n",
    "> ```python\n",
    "> transactions['day'] = transactions['tran_date'].apply(lambda date: date.split('-')[0])\n",
    "> ```\n",
    "> \n",
    "> Ce genre de syntaxe est très pratique et très souvent utilisée pour le nettoyage de bases de données.\n",
    ">\n",
    "> <br>\n",
    "> \n",
    "> La colonne `prod_subcat_code` de `transactions` dépend de la colonne `prod_cat_code` car elle désigne une **sous-catégorie** de produit. <br>\n",
    "> Il serait plus logique d'avoir la catégorie et sous-catégorie d'un produit dans la même variable.\n",
    "> \n",
    "> Pour cela, nous allons fusionner les valeurs de ces deux colonnes :\n",
    ">> * Nous allons d'abord convertir les valeurs de ces deux colonnes en chaîne de caractères à l'aide de la méthode **`astype`**.\n",
    ">> \n",
    ">> \n",
    ">> * Ensuite, nous allons concaténer ces chaînes pour avoir un unique code représentant la catégorie et sous-catégorie. Ceci peut se faire de la façon suivante :\n",
    ">> \n",
    ">> ```python\n",
    ">> chaine1 = \"Je pense\"\n",
    ">> chaine2 = \"donc je suis.\"\n",
    ">> \n",
    ">> # Concaténation des deux chaînes en les séparant par un espace\n",
    ">> print(chaine1 + \" \" + chaine2)\n",
    ">> >>> Je pense donc je suis.\n",
    ">> ```\n",
    "> \n",
    "> Pour appliquer une fonction lambda sur une ligne entière, il faut spécifier l'argument **`axis = 1`** dans la méthode `apply`. <br>\n",
    "> Dans la fonction elle-même, les colonnes de la ligne peuvent être accédées comme sur un `DataFrame` :\n",
    "> \n",
    "> ```python\n",
    "> # Calcul du prix unitaire d'un produit\n",
    "> transactions.apply(lambda row: row['total_amt'] / row['qty'], axis = 1)\n",
    "> ```\n",
    "\n",
    "* **(m)** À l'aide d'une fonction `lambda` appliquée sur `transactions`, créer une colonne **`'prod_cat'`** dans `transactions` contenant la concaténation des valeurs de `prod_cat_code` et `prod_subcat_code` séparées par un tiret `'-'`. N'oubliez pas de convertir les valeurs en chaînes de caractères.\n",
    "> L'affichage de cette colonne doit être le suivant :\n",
    "> \n",
    "> ```\n",
    "transaction_id\n",
    "80712190438     1-1\n",
    "29258453508     3-5\n",
    "51750724947     5-6\n",
    "93274880719    6-11\n",
    "51750724947     5-6\n",
    "               ... \n",
    "94340757522    5-12\n",
    "89780862956     1-4\n",
    "85115299378     6-2\n",
    "72870271171    5-11\n",
    "77960931771    5-11\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dst-cell-id": "44a9edc9-b791-4308-b827-654b4edfe82d"
   },
   "outputs": [],
   "source": [
    "# Insérez votre code ici \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "dst-cell-id": "c1d916e5-077b-4079-89d9-722860f3d0fb",
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "transactions['prod_cat'] = transactions.astype('str').apply(lambda row: row['prod_cat_code']+'-'+row['prod_subcat_code'],\n",
    "                                                            axis = 1)\n",
    "\n",
    "print(transactions['prod_cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "dst-cell-id": "ff8f3c72-22a0-4faf-a3d1-2c811f967256",
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 2. Gestion des valeurs manquantes\n",
    "\n",
    "> Une **valeur manquante** est soit :\n",
    ">> * Une valeur non renseignée.\n",
    ">>\n",
    ">>\n",
    ">> * Une valeur qui n'existe pas. En général, elles sont issues de calculs mathématiques n'ayant pas de solution (une division par zéro par exemple).\n",
    ">\n",
    "> Une valeur manquante apparaît sous la dénomination **NaN** (\"**N**ot **a** **N**umber\") dans un `DataFrame`.\n",
    ">\n",
    "> Dans cette partie, nous allons voir plusieurs méthodes pour :\n",
    ">> * La **détection** des valeurs manquantes (méthodes `isna` et `any`).\n",
    ">>\n",
    ">>\n",
    ">> * Le **remplacement** de ces valeurs (méthode `fillna`).\n",
    ">>\n",
    ">>\n",
    ">> * La **suppression** des valeurs manquantes (méthode `dropna`).\n",
    ">\n",
    "> Dans un des exercices précédents, nous avons utilisé la méthode `replace` de `transactions` pour remplacer les valeurs manquantes par `0`. <br>\n",
    "> Cette approche manque de rigueur et il ne faut pas procéder de cette façon en pratique.\n",
    ">\n",
    "> Pour cette raison, nous allons réimporter la version brute de `transactions` pour annuler les étapes que nous avons faites dans les exercices précédents.\n",
    "\n",
    "* **(a)** Lancer la cellule suivante pour réimporter `transactions`, enlever les doublons et renommer ses colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "dst-cell-id": "00d7c13f-fbbe-4786-b6f8-9fac17b3fe12",
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Importation des données\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep =',', index_col = \"transaction_id\")\n",
    "\n",
    "# Suppression des doublons\n",
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "# Changement de nom des colonnes\n",
    "new_names =  {'Store_type' : 'store_type',\n",
    "              'Qty'        : 'qty',\n",
    "              'Rate'       : 'rate',\n",
    "              'Tax'        : 'tax'}\n",
    "\n",
    "transactions = transactions.rename(new_names, axis = 1)\n",
    "\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "dst-cell-id": "320ff6ff-52ba-4d7e-bdbe-98df78d667d4",
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Détection des valeurs manquantes (méthodes `isna` et `any`)\n",
    "\n",
    "> La méthode **`isna`** d'un `DataFrame` détecte ses valeurs manquantes. Cette méthode ne prend pas d'arguments.\n",
    "> \n",
    "> Cette méthode retourne le même `DataFrame` dont les valeurs sont :\n",
    ">> * **`True`** si la case du tableau originale est une valeur manquante (`np.nan`).\n",
    ">>\n",
    ">>\n",
    ">> * **`False`** sinon.\n",
    ">\n",
    "> <br>\n",
    "> \n",
    ">  <img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/is_null.png\" width=\"750\">\n",
    ">\n",
    "> <br>\n",
    ">\n",
    "> Puisque la méthode `isna` renvoie un `DataFrame`, nous pouvons l'utiliser avec d'autres méthodes de la classe `DataFrame` pour avoir des informations plus précises :\n",
    ">> * La méthode `any` avec son argument `axis` permet de déterminer **quelles colonnes** (`axis = 0`) ou **quelles lignes** (`axis = 1`) contiennent au moins une valeur manquante.\n",
    ">>    \n",
    ">>\n",
    ">> * La méthode `sum` compte le nombre de valeurs manquantes par colonne ou lignes (en spécifiant l'argument `axis`). Il est possible d'utiliser d'autres méthodes statistiques comme `mean`, `max`, `argmax`, etc...\n",
    ">\n",
    "> Voici de nombreux exemples d'utilisation des méthodes `any` et `sum` avec `isna` :\n",
    ">\n",
    "> On reprend le `DataFrame` **`df`** de l'illustration précédente :\n",
    ">\n",
    "> |    | Nom     | Pays      |   Age |\n",
    "> |---:|:--------|:----------|------:|\n",
    "> |  0 | NaN     | Australie |   NaN |\n",
    "> |  1 | Duchamp | France    |    25 |\n",
    "> |  2 | Hana    | Japon     |    54 |\n",
    ">\n",
    "> L'instruction `df.isna()` renvoie :\n",
    ">\n",
    ">\n",
    "> |    |   Nom   |   Pays |   Age |\n",
    "> |---:|--------:|-------:|------:|\n",
    "> |  0 |   True  | False  | True  |\n",
    "> |  1 |   False | False  | False |\n",
    "> |  2 |   False | False  | False |\n",
    "> \n",
    "> ```python\n",
    "> # On détecte les COLONNES contenant au moins une valeur manquante\n",
    "> df.isna().any(axis = 0) \n",
    ">\n",
    "> >>> Nom      True\n",
    ">     Pays     False\n",
    ">     Age      True\n",
    "> ```\n",
    ">\n",
    "> ```python\n",
    "> # On détecte les LIGNES contenant au moins une valeur manquante\n",
    "> df.isna().any(axis = 1) \n",
    ">\n",
    "> >>> 0     True\n",
    ">     1    False\n",
    ">     2    False\n",
    "> ```\n",
    "> ```python\n",
    "> # On utilise l'indexation conditionnelle pour afficher les entrées\n",
    "> # contenant des valeurs manquantes\n",
    "> \n",
    "> df[df.isna().any(axis = 1)]\n",
    "> ```\n",
    "> ce qui renvoie le `DataFrame` :\n",
    ">\n",
    "> |    |   Nom | Pays      |   Age |\n",
    "> |---:|------:|:----------|------:|\n",
    "> |  0 |   NaN | Australie |   NaN |\n",
    ">\n",
    "> ```python\n",
    "> # On compte le nombre de valeurs manquantes pour chaque COLONNE\n",
    "> df.isnull().sum(axis = 0) #Les fonctions isnull et isna sont strictement équivalentes\n",
    ">\n",
    "> >>> Nom     1\n",
    ">     Pays    0\n",
    ">     Age     1\n",
    "> ```\n",
    ">\n",
    "> ```python\n",
    "> # On compte le nombre de valeurs manquantes pour chaque LIGNE\n",
    "> df.isnull().sum(axis = 1) \n",
    "> \n",
    "> >>> 0    2\n",
    ">     1    0\n",
    ">     2    0\n",
    "> ```\n",
    "\n",
    "* **(b)** Combien de colonnes du `DataFrame` `transactions` contiennent des valeurs manquantes ?\n",
    "\n",
    "\n",
    "* **(c)** Combien d'entrées de `transactions` contiennent des valeurs manquantes ? Vous pourrez suivre la méthode `any` avec la méthode `sum`.\n",
    "\n",
    "\n",
    "* **(d)** Quelle colonne de `transactions` contient **le plus** de valeurs manquantes ?\n",
    "\n",
    "\n",
    "* **(e)** Afficher les entrées de `transactions` qui contiennent au moins une valeur manquante dans les colonnes `'rate'`, `'tax'` et `'total_amt'`. Que remarquez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dst-cell-id": "d73df489-c3a4-4f1a-8796-e723198a3ada"
   },
   "outputs": [],
   "source": [
    "## Insérez votre code ici \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "dst-cell-id": "e1d3b883-38ec-41f5-bd4d-789e2df82b1c",
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "# Quelles sont les colonnes qui contiennent des NANs\n",
    "colonnes_na = transactions.isna().any(axis = 0)\n",
    "\n",
    "print(colonnes_na.sum(), \"colonnes de transactions contiennent des NANs. \\n\")\n",
    "\n",
    "# Quelles sont les lignes qui contiennent des NANs\n",
    "lignes_na = transactions.isna().any(axis = 1)\n",
    "\n",
    "print(lignes_na.sum(), \"lignes de transactions contiennent des NANs. \\n\")\n",
    "\n",
    "# Nombre de NANs par colonne\n",
    "colonnes_nbna = transactions.isna().sum(axis = 0)\n",
    "\n",
    "print(\"La colonne contenant le plus de NANs est:\", colonnes_nbna.idxmax())\n",
    "\n",
    "# Affichage des 10 premières entrées contenant au moins un NAN dans 'rate', 'tax' ou 'total_amt'\n",
    "transactions[transactions[['rate', 'tax', 'total_amt']].isna().any(axis = 1)].head(10)\n",
    "\n",
    "# Les trois variables sont toujours manquantes ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "dst-cell-id": "1958e738-e991-4dc8-a517-d21b3e527b61",
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Remplacement des valeurs manquantes (méthode `fillna`)\n",
    "\n",
    "> La méthode `fillna` permet de remplacer les valeurs manquantes d'un `DataFrame` par des valeurs de notre choix.\n",
    ">\n",
    ">```python\n",
    "> # On remplace tous les NANs du DataFrame par des zéros\n",
    ">  df.fillna(0) \n",
    ">\n",
    "> # On remplace les NANs de chaque colonne numérique par la moyenne sur cette colonne\n",
    ">  df.fillna(df.mean())  # df.mean() peut être remplacée par n'importe quelle méthode statistique.\n",
    ">```\n",
    ">\n",
    "> Il est courant de remplacer les valeurs manquantes d'une colonne de **type numérique** avec des **statistiques** comme :\n",
    ">> * La **moyenne** : `mean`.\n",
    ">>\n",
    ">>\n",
    ">> * La **médiane** : `median`.\n",
    ">>\n",
    ">>\n",
    ">> * Le **minimum/maximum** : `min`/`max`.\n",
    ">\n",
    "> Pour les colonnes de type catégorielle, on remplacera les valeurs manquantes avec :\n",
    ">> * Le **mode**, i.e. la modalité la plus fréquente : `mode`.\n",
    ">>\n",
    ">>\n",
    ">> * Une **constante** ou catégorie arbitraire : `0`, `-1`.\n",
    ">\n",
    "> Pour éviter de faire des erreurs de remplacement, il est fortement conseillé de **sélectionner les bonnes colonnes** avant d'utiliser la méthode `fillna`.\n",
    "\n",
    "* Si vous faites des erreurs dans l'exercice suivant, vous pouvez réimporter `transactions` à l'aide de la cellule suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "dst-cell-id": "63988a60-9634-4873-a6d7-a4b48da7ffb7",
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Importation des données\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep =',', index_col = \"transaction_id\")\n",
    "\n",
    "# Suppression des doublons\n",
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "# Changement de nom des colonnes\n",
    "new_names =  {'Store_type' : 'store_type',\n",
    "              'Qty'        : 'qty',\n",
    "              'Rate'       : 'rate',\n",
    "              'Tax'        : 'tax'}\n",
    "\n",
    "transactions = transactions.rename(new_names, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "dst-cell-id": "361d6c39-eef6-4c1e-906a-a70476f45097",
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* **(f)** Remplacer les valeurs manquantes de la colonne **`prod_subcat_code`** de `transactions` par `-1`.\n",
    "\n",
    "\n",
    "* **(g)** Déterminer **la modalité la plus fréquente** (le mode) de la colonne **`store_type`** de `transactions`.\n",
    "\n",
    "\n",
    "* **(h)** Remplacer les valeurs manquantes de la colonne `store_type` par cette modalité. On accède à la valeur de cette modalité **à l'indice 0** de la `Series` renvoyée par `mode`.\n",
    "\n",
    "\n",
    "* **(i)** Vérifier que les colonnes `prod_subcat_code` et `store_type` de `transactions` ne contiennent plus de valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dst-cell-id": "a6803f9d-f149-427e-a712-f80c3bdcf221"
   },
   "outputs": [],
   "source": [
    "## Insérez votre code ici \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "dst-cell-id": "97d8fb8b-e8f3-4e33-81b1-49a716826156",
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "# On remplace les NANs de 'prod_subcat_code' par -1\n",
    "transactions['prod_subcat_code'] = transactions['prod_subcat_code'].fillna(-1)\n",
    "\n",
    "# On détermine le mode de 'store_type'\n",
    "store_type_mode = transactions['store_type'].mode()\n",
    "print(\"La modalité la plus fréquente de 'store_type' est:\", store_type_mode[0])\n",
    "\n",
    "# On remplace les NANs de 'store_type' par son mode\n",
    "transactions['store_type'] = transactions['store_type'].fillna(transactions['store_type'].mode()[0])\n",
    "\n",
    "# On vérifie que ces deux colonnes ne contiennent plus de NANs\n",
    "transactions[['prod_subcat_code', 'store_type']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "dst-cell-id": "b026cee9-aaf9-4efe-be8e-b8e5a4659375",
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Suppression des valeurs manquantes (méthode `dropna`)\n",
    "\n",
    "> La méthode `dropna` permet de supprimer les lignes ou colonnes contenant des valeurs manquantes.\n",
    ">\n",
    "> L'en-tête de la méthode est la suivante : `dropna(axis, how, subset, ..)`\n",
    ">> * Le paramètre **`axis`** précise si on doit supprimer des lignes ou des colonnes (**`0`** pour les lignes, **`1`** pour les colonnes).\n",
    ">>\n",
    ">>\n",
    ">> * Le paramètre **`how`** permet de préciser comment les lignes (ou les colonnes) sont supprimées :\n",
    ">>> * **`how = 'any'`**: On supprime la ligne (ou colonne) si elle contient **au moins une** valeur manquante.\n",
    ">>>\n",
    ">>>\n",
    ">>> * **`how = 'all'`** : On supprime la ligne (ou colonne) si elle ne contient **que** des valeurs manquantes.\n",
    ">>\n",
    ">>\n",
    ">> * Le paramètre **`subset`** permet de préciser les colonnes/lignes sur lesquelles on effectue la recherche de valeurs manquantes.\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Exemple :</span><br> \n",
    ">```python\n",
    "> # On supprime toutes les lignes contenant au moins une valeur manquante\n",
    "> df = df.dropna(axis = 0, how = 'any')\n",
    ">\n",
    "> # On supprime les colonnes vides \n",
    "> df = df.dropna(axis = 1, how = 'all') \n",
    ">\n",
    "> # On supprime les lignes ayant des valeurs manquantes dans les 3 colonnes 'col2','col3' et 'col4'\n",
    ">  df.dropna(axis = 0, how = 'all', subset = ['col2','col3','col4']) \n",
    "> ```\n",
    ">\n",
    "> Comme pour les autres méthodes de remplacement de valeurs d'un `DataFrame`, l'argument `inplace` peut être utilisé avec grande précaution pour effectuer la modification directement sans réassignation.\n",
    "\n",
    "Les données de transactions pour lesquelles le montant de la transaction n'est pas renseigné ne nous sont pas intéressantes. Pour cette raison : \n",
    "\n",
    "* **(j)** Supprimer les entrées de `transactions` pour lesquelles les colonnes **`rate`**, **`tax`** et **`total_amt`** sont **simultanément** vides.\n",
    "\n",
    "\n",
    "* **(k)** Vérifier que les colonnes de `transactions` **ne contiennent plus** de valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dst-cell-id": "216fd307-10f8-4879-a5d8-93e2a6844515"
   },
   "outputs": [],
   "source": [
    "## Insérez votre code ici \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "dst-cell-id": "8703786c-c003-48ec-89ca-0bf2fb05c27a",
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "transactions = transactions.dropna(axis = 0, how = 'all', subset = ['rate', 'tax', 'total_amt'])\n",
    "\n",
    "transactions.isna().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "dst-cell-id": "199c8070-3d61-474e-8574-08391b7cf247",
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Conclusion et récap\n",
    "\n",
    "> Dans ce chapitre nous avons vu les méthodes essentielles du module `pandas` afin de nettoyer un dataset et gérer les valeurs manquantes (`NaN`). \n",
    ">\n",
    "> Cette étape de préparation d'un dataset est **toujours** la première étape d'un projet data.\n",
    ">\n",
    "> Concernant le **nettoyage des données**, nous avons ainsi appris à :\n",
    ">\n",
    ">> * Repérer et supprimer les doublons d'un `DataFrame` grâce aux méthodes **`duplicated`** et **`drop_duplicates`**.\n",
    ">>\n",
    ">>\n",
    ">> * Modifier les éléments d'un `DataFrame` et leur type à l'aide des méthodes **`replace`**, **`rename`** et **`astype`**.\n",
    ">>\n",
    ">>\n",
    ">> * Appliquer une fonction à un `DataFrame` avec la méthode **`apply`** et la clause **`lambda`**.\n",
    ">\n",
    "> Concernant la **gestion des valeurs manquantes**, nous avons appris à :\n",
    ">> * Les **détecter** grâce à la méthode **`isna`** suivie des méthodes **`any`** et **`sum`**.\n",
    ">>\n",
    ">>\n",
    ">> * Les **remplacer** à l'aide de la méthode **`fillna`** et des **méthodes statistiques**.\n",
    ">>\n",
    ">>\n",
    ">> * Les **supprimer** grâce à la méthode **`dropna`**.\n",
    ">\n",
    "> Dans le notebook suivant, vous verrez d'autres manipulations de `DataFrame` pour une **exploration** des données plus avancées."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "n_questions": 1,
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "owner": "DataScientest"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
